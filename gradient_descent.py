import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, r2_score

def SSR(y_true, y_pred):
    if y_true.shape != y_pred.shape:
        return None
    return np.sum((y_true - y_pred)**2)

def gradient_b(x, y, m, b):
    residuals = y - (m*x + b)
    return (-2 / len(x)) * np.sum(residuals)

def gradient_m(x, y, m, b):
    residuals = y - (m*x + b)
    return (-2 / len(x)) * np.sum(x * residuals)

def predict_y(x, m, b):
    return m*x + b

def gradient_descent(X, y, ITERATIONS, LEARNING_RATE):
    X = np.array(X, dtype=float)
    y = np.array(y, dtype=float)

    m = 1
    b = 0 
    
    for _ in range(ITERATIONS):
        grad_m = gradient_m(X, y, m, b)
        grad_b = gradient_b(X,y,m,b)
        
        step_m = grad_m * LEARNING_RATE
        step_b = grad_b * LEARNING_RATE
        
        m = (m - step_m)
        b = (b- step_b)
        
        y_pred = predict_y(X,m,b)
        if abs(step_m) < 0.001 and abs(step_b) < 0.001: 
            print(f"Iterations: {_}")
            break
            
    return y_pred, m, b

df = pd.read_csv("Car_weight.csv")
X_values = df["weight"]
y_values = df["mpg"]

X_train, X_test, y_train, y_test = train_test_split(X_values, y_values, random_state=42, test_size = 0.2)

#Normalize X 
X_mean = X_train.mean()
X_std = X_train.std()
X_train = (X_train - X_mean) / X_std

X_test_scaled = (X_test - X_mean) / X_std

ITERATIONS = 1000000
LEARNING_RATE = 0.001
y_pred, m, b = gradient_descent(X_train, y_train,  ITERATIONS, LEARNING_RATE)

y_test_pred = predict_y(X_test_scaled, m, b)

print("Mine:")
print("MSE:", mean_squared_error(y_test, y_test_pred))
print("R²:", r2_score(y_test, y_test_pred))
print(" Intercept (b):", b)
print(" Slope (m):", m)

# Plot regression line

# # Scatter original data
# plt.scatter(X_values, y_values, label="Data")

# x_line = np.linspace(X_values.min(), X_values.max(), 100)
# x_line_scaled = (x_line - X_mean) / X_std
# y_line = m * x_line_scaled + b

# plt.plot(x_line, y_line, color ="orange", label="Regression Line")

# plt.xlabel("Weight")
# plt.ylabel("MPG")
# plt.title("Linear Regression Fit (from scratch)")
# plt.legend()
# plt.show()

# Compare to SkLearn
model = LinearRegression()
model.fit(X_train.values.reshape(-1,1), y_train)

sk_y_pred = model.predict(X_test_scaled.values.reshape(-1,1))

print("\n Sklearn Comparison")
print(" MSE:", mean_squared_error(y_test, sk_y_pred))
print(" R²:", r2_score(y_test, sk_y_pred))
print(" Intercept (b):", model.intercept_)
print(" Slope (m):", model.coef_[0])



# 3D Loss Surface -- following code generated by AI
m_vals = np.linspace(m - 5, m + 5, 100)
b_vals = np.linspace(b - 5, b + 5, 100)
M, B = np.meshgrid(m_vals, b_vals)

Z = np.zeros_like(M)
for i in range(M.shape[0]):
    for j in range(M.shape[1]):
        y_hat = predict_y(X_train, M[i, j], B[i, j])
        Z[i, j] = SSR(y_train, y_hat)

fig = plt.figure(figsize=(10,7))
ax = fig.add_subplot(111, projection='3d')
ax.plot_surface(M, B, Z, alpha=0.7)
ax.set_xlabel("m")
ax.set_ylabel("b")
ax.set_zlabel("SSR")
ax.set_title("Loss Surface: SSR(m, b)")
plt.show()